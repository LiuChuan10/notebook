智能FAQ文档（版本：V1.1）
目 录
一.	算法问题	1
1.1 算法通识问题	1
1.1.1 GPU算法和CPU算法有什么本质区别？	1
1.1.2 深度学习性能为何无法达到100%？	1
1.1.3 数据对于深度学习来说为什么很重要？	2
1.1.4 什么是模型训练和推理？两者有什么不一样？	2
1.1.5 模型训练和推理对于硬件要求一样么？	2
1.1.6 模型精度指的是什么？比如INT8、FP16？	2
1.1.7 模型精度如INT8、FP16有什么区别？	3
1.1.8 衡量算法精度常见的指标有哪些？	3
1.1.9 不同指标在项目中怎么去使用？	4
1.1.10 TensorFlow、PyTorch、Caffe、MXNet等是什么？它在算法训练中的作用是什么？	5
1.1.11 我们常说的深度学习网络是不是CNN、RNN、GNN、GRU等？它在算法训练中的作用是什么？	5
1.1.12 常见的深度学习方法有哪些？它在算法训练中的作用是什么？	5
1.1.13 我们常说的深度学习的调参，是在什么时候调，调整哪些参数，要怎么调？	6
1.1.14 常见的深度学习损失函数有哪些，它在算法训练中的作用是什么？	7
1.1.15 深度学习框架、深度学习网络、深度学习方法、损失函数之间的关系是什么样的？	7
1.1.16 开发一个新的算法涉及到哪些流程？	7
1.1.17 训练一个新的模型涉及到哪些流程？	7
1.1.18 如果选择相同的深度学习框架、深度学习网络和深度学习方法，如何能够训练不同的算法，比如说语义分割算法、实体分割算法、人脸识别算法、车辆识别算法？	8
1.2 算法应用问题	9
1.2.1 算法资源有没有涉及到安全和保密的资源，如算法配置、算法接口？	9
1.2.2 什么是人脸检测？什么是人脸比对？	10
1.2.3 图像质量对人脸识别是否有影响？	10
1.2.4 人脸抓拍为何会出现狗脸\车轮等非人脸？	10
1.2.5 为什么前端人脸抓拍成功的数据，后端设备入库失败？	10
1.2.6 与正常成年人相比，老人小孩人脸识别效果如何？	11
1.2.7 人脸识别中人脸关键点的数量是不是越多越好？	11
二.	大模型问题	11
2.1 大模型通识问题	11
2.1.1 大模型和小模型有什么区别？	11
2.1.2 CNN和transformer有什么区别？	12
2.1.3 大模型训练和原先深度学习小模型训练有什么区别？	12
2.1.4 怎么理解大模型的参数和数据？两者之间有什么样的关系？	13
2.1.5 大模型开发过程中使用的工具链是什么？开发环境，开发工具，开发库？训练和推理使用的编程语言是什么？	14
2.1.6 基础大模型、行业大模型、任务大模型有什么区别？	14
2.1.7 各个厂家的基础大模型区别大吗？	14
2.1.8 什么是知识蒸馏？	15
2.1.9 大模型与蒸馏后的小模型的区别？	15
2.1.10 关于大模型蒸馏成小模型的技术，各个厂家的方案是否一样？	15
2.1.11 语言大模型、视觉大模型、多模态大模型之间的区别？	16
2.1.12 通用大模型到行业大模型，输入的是带标注的数据吗？	16
2.1.13 大模型训练各环节有多大规模数据输入？是否有标注？在微调阶段数据量对模型性能的影响（多少量级是门槛？）	16
2.1.14 视觉大模型起训数据量减少多少？人工标注提效多少？	17
2.1.15 视觉大模型一定要输入数据吗？Zero-shot可行吗？为什么通用大模型不能解决所有问题？	17
2.1.16 用大模型是否可以降低算法对输入图片的要求？比如图片像素、目标大小、人脸瞳距等要求？	17
2.2 海康大模型基础问题	17
2.2.1 海康大模型名字叫什么？	17
2.2.2 海康大模型有什么技术优势？	17
2.2.3 海康大模型的瓶颈是什么？	18
2.2.4 海康大模型训练数据来源有哪些？	18
2.2.5 海康大模型的参数量有多少？	19
2.2.6 海康大模型底层的架构、参数量、算力要求是怎么样的？是否开源架构，代码层是否开放？？	19
2.2.7 海康大模型应用架构中，云端和边缘端大模型部署架构的区别，各自的优劣势？	19
2.2.8 小公司基于开源大模型的方案是否可以达到海康大模型同等的性能？	20
2.2.9 海康大模型如何保证数据的安全隐私性（业务中的数据主要在什么阶段使用，如何使用以及如何保证数据安全隐私）？	20
2.2.10 海康大模型针对虚假/内容失真的问题如何处理？幻觉问题是仅针对语言相关吗 ？	21
2.2.11 大模型对硬件设备有什么要求？是否支持在CPU上运行？	21
2.2.12 已部署的项目能不能升级到大模型？	21
2.2.13 以前的都是小模型，是否有必要都升级到大模型，大、小模型适用场景差异性？	21
2.2.14 客用户对大模型最直观的了解chatgpt、文心一言等，如何专业又易懂地向客用户介绍海康大模型？能讲出来区别和我们的专业性？	22
2.2.15 如果用越大的通用大模型，叠加行业数据，训练出来的行业大模型效果会越好吗？	22
2.3 海康大模型应用问题	22
2.3.1 海康大模型常见的的部署方式有哪些？对于设备有什么要求？	22
2.3.2 海康多模态大模型有哪些应用？	23
2.3.3 大模型和AI开放平台是怎么结合的？具体操作上和原来的AIOP算法有什么区别？在AI开放平台上如何区分？	23
2.3.4 海康大模型能否部署到第三方服务器？	23
2.3.5 第三方自研小模型能否使用海康大模型进行二次过滤？	23
2.3.6 一个算法里有多种标签，但是每个标签的素材量差距非常大，比如同样是鸟，麻雀素材很多，但老鹰素材很少，是否容易将老鹰识别成麻雀，同时检测时大模型能拉平衡么？	24
2.3.7 政府想要私有化部署大模型怎么实施？	24
2.3.8 有没有大模型的演示环境？	24
 
一.	算法问题
1.1 算法通识问题
1.1.1 GPU算法和CPU算法有什么本质区别？
CPU需要很强的通用性来处理各种不同的数据类型，但同时逻辑判断又会引入大量的分支跳转和中断的处理，所以这种通用性结构对于传统的编程计算模式非常适合。
GPU面对的是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境，支持对深度学习至关重要的并行计算能力，可比传统处理器更加快速，可加快了训练过程。
所以两者最主要的区别在于运算能力的不同，在相同运算能力的前提下，算法未经裁剪两者的性能是一样的；但是由于CPU受限于其运算能力，在产品化落地的过程中会做模型精简的工作，此后两者的算法性能是不同的，GPU算法性能会优于CPU算法。
一般情况下CPU算法基于传统模式识别技术实现，GPU算法基于深度学习技术实现。
1.1.2 深度学习性能为何无法达到100%？
性能无法达到100%不仅是深度学习的问题，同时也是模式识别，甚至认知学（包括人的认知）都会有的问题，一般来说，我们将人的认知水平能够做到的极限作为算法在某个领域的上限，比如Imagenet数据集，有研究团队做过人的认知统计，通过志愿者的人工识别，imagenet的数据集的平均错误率在3%以上， 所以针对imagenet的算法错误率如果跌破3%，我们就认为在该领域，机器认知超过了人类；
另外还有一个空间子集问题，因为所有的机器学习方法（包括统计学习，深度学习等等），都是基于归纳法的，归纳法有一个问题，就是训练数据不管再大，始终只是样本空间的一个子集，在这个子集上我们训练到100%是有可能的，但是我们的应用中，往往面对的是完整空间，比如说用100w人的人脸去训练一个识别模型，那这100w样本上算法能训练到100%，但是真实场景，哪怕是同样的一个人来拍的照片，其实都是在样本空间下的一个新样本，这个时候，归纳法是没有办法保证100%的。否则，根据以往的数据拟合的模型，炒股票也能百发百中。
1.1.3 数据对于深度学习来说为什么很重要？
对于深度学习来说，深度学习的性能受数据驱动，它需要海量的数据进行训练，数据规模和质量一定程度决定了算法性能上限。
1.1.4 什么是模型训练和推理？两者有什么不一样？
模型训练是指利用大量已知的数据，通过特定的算法和优化方法，调整模型的参数，使得模型能够尽可能准确地对新的数据进行预测或分类等任务。训练过程中通常需要大量的计算资源、时间和海量的数据。
模型推理是指使用已经训练好的模型对新的未知数据进行预测或分析的过程。推理过程中对计算资源的要求相对较低，但是实时性要求较高，通常是在实际应用中实时进行的。
模型训练是为了让模型学习数据中的模式和规律，而模型推理则是利用训练好的模型对新数据进行实际的应用和预测。
1.1.5 模型训练和推理对于硬件要求一样么？
一般来说训练和推理的GPU卡是分开的，对于硬件要求不一样。
有些芯片只能支持推理而不支持训练，主要是受计算精度（如int8、fp16运算）和软件栈等因素的限制。
1.1.6 模型精度指的是什么？比如INT8、FP16？ 
在深度学习和计算机视觉领域中，FP16、INT8是常见的数据类型或精度表示方式。
FP16（半精度浮点数），是一种被计算机使用的二进制浮点数据类型。FP即“Floating Point”，表示“浮点运算”，16表示“半精度浮点数”。FP16在计算机存储器中占用2个字节（16 bits），利用“浮点”（浮动小数点）的方法，可以表示一个范围很大的数值；适用于模型推理任务。
INT8（8位整数），是一种定点计算方式，代表了整数运算，一般是由浮点运算量化而来。二进制中的一个“0”或一个“1”叫1位（bit），INT8指用8位（8 bits）表示一个数字，在计算机存储器中占用1个字节；适用于模型推理和训练任务。
1.1.7 模型精度如INT8、FP16有什么区别？
从精度上来说：FP16＞INT8；
从计算耗时上来说：FP16＞INT8，理论值情况下，大部分芯片FP16为INT8的2倍（部分端侧芯片可以做到4倍）；
从内存占用上来说：FP16＞INT8，理论值情况下FP16为INT8的2倍。
1.1.8 衡量算法精度常见的指标有哪些？
衡量算法精度常见的指标有检出率、检准率、准确率、每天每路误报数、正报保留率、误报去除率、Rank(N)命中率等，不同指标的定义如下。
 
检出率/召回率（Recall）：
衡量在所有实际为正确的样本中，我们成功预测出多少的比例。这也可以被理解为查全率，即我们找回了多少真正的正样本。计算公式为：
Recall = TP / (TP + FN)
检准率/精确率（Precision）：
衡量我们预测为正确的样本中，实际上确实为正确的比例。换句话说，它反映了我们预测的准确性。计算公式为：
Precision = TP / (TP + FP)
准确率（Accuracy）：
衡量正确预测的样本占总样本的比例。计算公式为：
Accuracy =(TP + TN) / (TP + TN + FP + FN)
每天每路误报数：
计算公式如下：
每天每路误报数=误报数/天数/分析路数
正报保留率：
在相同的时间范围内，原事件正报数为A，加入二次过滤的版本后事件正报数为B。计算公式为：
正报保留率=B/A*100%
误报去除率：
在相同的时间范围内，原事件误报数为A，加入二次过滤的版本后事件误报数为B。计算公式为：
误报去除率=(A-B)/A*100%
Rank(N)命中率： 
衡量搜索结果中前N位命中目标的概率，计算公式为：
Rank(N)命中率=前N位命中正确结果数目/总的测试样本数目
1.1.9 不同指标在项目中怎么去使用？
1、检出率、检准率、准确率：在常规的实际项目测试中可以使用，验收过程中可以通过模拟真实事件来进行评测；
2、每天每路误报数：在实际项目中，针对小概率事件的情况下可以使用；比如厂房烟火识别，实际使用中基本没有正报，效果指标评判可以引导为每天每路误报数；
3、正报保留率、误报去除率：一般在大模型二次过滤项目中使用，用来评测大模型的误报过滤能力；
4、Rank(N)命中率：一般在检索类应用中使用，比如结构化特征检索、人脸静态检索。
1.1.10 TensorFlow、PyTorch、Caffe、MXNet等是什么？它在算法训练中的作用是什么？
我们常说的TensorFlow、PyTorch、Caffe、MXNet等是常见的深度学习框架。
深度学习框架在深度学习领域中起着至关重要的作用，它为开发者提供了高效的计算环境、简化了模型开发流程、促进了模型复用和共享，同时支持多种深度学习任务和算法，推动了深度学习技术的快速发展和广泛应用
1.1.11 我们常说的深度学习网络是不是CNN、RNN、GNN、GRU等？它在算法训练中的作用是什么？
我们常说的深度学习网络就是CNN、RNN、GNN、GRU等，同时LSTM（长短期记忆网络）、GAN（生成对抗网络）、transformer、目标检测网络（如YOLO、SSD）等也是常见的深度学习网络。
深度学习网络在算法训练中的具有以下重要作用，包括：
1、特征提取与表示学习，自动学习特征、高纬度数据降维
2、模型的表达能力增强，复杂函数逼近、非线性建模
3、优化算法与参数调整，梯度下降优化、超参数调整
4、泛化能力与鲁棒性提升，数据正确、正则化技术
5、模型的可解释性探索，特征可视化、解释性方法
1.1.12 常见的深度学习方法有哪些？它在算法训练中的作用是什么？
半监督、有监督、无监督、强化学习是常见的4种深度学习方法，深度学习方法在模型训练中的作用主要体现在学习任务特定的表示、提高泛化能力、调整模型参数、特征抽象和层级表示、以及自适应性等方面。
‌1、学习任务特定的表示：深度学习模型通过训练学习任务相关的特征和表示。在训练过程中，模型通过调整权重和参数，自动学习如何从输入数据中提取有用的特征，这些特征对于任务的成功执行至关重要。
2、提高泛化能力：训练使模型具有泛化能力，即在面对未见过的数据时能够做出良好的预测。通过在大量训练数据上学习，模型能够捕捉数据中的通用模式，而不是仅仅记住训练集中的具体样本。
3、‌调整模型参数：深度学习模型通常包含大量参数，通过训练，这些参数可以被调整以最大程度地减小模型在训练数据上的预测误差。优化算法通过最小化损失函数来调整参数，使模型的输出更接近真实标签。
4、‌特征抽象和层级表示：深度学习模型通过多层次的神经网络学习数据的层级表示和抽象，从而能够理解复杂的关系和模式。这种层级表示有助于提高模型对输入数据的理解能力。
‌5、自适应性：深度学习模型在训练过程中能够适应不同的数据分布和模式。通过反复调整模型参数，使其能够适应各种输入条件，增强了模型的灵活性。
深度学习方法通过上述作用，使得模型能够更好地处理和分析复杂数据，提高预测的准确性和效率，解决各种实际问题。
1.1.13 我们常说的深度学习的调参，是在什么时候调，调整哪些参数，要怎么调？
在深度学习中，参数和超参数的概念是不同的，两者的定义如下：
1. 参数，参数是深度学习模型在训练过程中通过优化算法自动学习得到的变量。它们决定了模型对输入数据的具体处理方式和输出结果。权重和偏置就是典型的参数。
2. 超参数，超参数是在模型训练之前由用户手动设置的参数，它们不能通过训练算法自动学习得到。超参数控制着模型的结构、训练过程和性能表现。学习率、批次大小、网络层数、神经元数量等都是典型的超参数。
深度学习中的调参实际上不是调“参数”，而是调“超参数”。超参数是在模型训练之前由用户手动设置的，它们不会在训练过程中更新。
超参数的调整通常需要通过实验和经验来确定。用户可以尝试不同的超参数组合，观察模型的性能表现，然后选择最优的超参数设置。常见的超参数调整方法包括网格搜索、随机搜索、贝叶斯优化等。这些方法可以在一定程度上自动化超参数的调整过程，但仍然需要用户对超参数的范围和搜索策略进行合理的设置。
1.1.14 常见的深度学习损失函数有哪些，它在算法训练中的作用是什么？ 
损失函数是用来衡量模型预测值与真实值之间差异的函数，它的目标是最小化这个差异，使得模型的预测结果尽可能接近真实值。在模型训练中它可以起到衡量模型性能及指导模型优化的左右。
常见的损失函数包括均方误差（MSE）、平均绝对误差（MAE）、交叉熵损失、二元交叉熵损失、带对数的二元交叉熵损失、Kullback-Leibler散度、负对数似然损失和铰链损失等。
1.1.15 深度学习框架、深度学习网络、深度学习方法、损失函数之间的关系是什么样的？
深度学习框架为深度学习网络的构建、训练和部署提供了基础平台和工具。
深度学习框架是深度学习方法的实现载体。
深度学习方法是用于训练和优化深度学习网络的手段。
损失函数用于衡量深度学习网络的性能及指导网络优化。
1.1.16 开发一个新的算法涉及到哪些流程？
一般情况下，开发一个新的算法会涉及到需求定义、算法设计、算法开发、算法部署几个关键流程。
1.1.17 训练一个新的模型涉及到哪些流程？
一般情况下，训练一个新的模型会涉及到数据准备、模型选择与设计、模型训练及调优、部署应用几个关键流程。
1.1.18 如果选择相同的深度学习框架、深度学习网络和深度学习方法，如何能够训练不同的算法，比如说语义分割算法、实体分割算法、人脸识别算法、车辆识别算法？
这个问题本身是不准确的，不同的算法可能使用不同的深度学习框架、深度学习网络和深度学习方法，也可能有部分重叠。以下展开做详细介绍：
1、深度学习框架
1）不同算法可能使用不同框架
一些特定领域的算法可能由于性能需求、开发团队偏好等原因选择特定的深度学习框架。例如，在自然语言处理领域，一些研究人员可能更倾向于使用 PyTorch，因为它在灵活性和动态计算图方面表现出色，适合快速实验和开发复杂的语言模型；而在大规模工业部署中，TensorFlow 可能更受青睐，因为它具有更好的生产环境支持和性能优化。
同时，某些算法可能对分布式训练有较高要求，如大规模图像分类或语音识别任务，这时可能会选择支持高效分布式训练的框架，如Horovod结合 TensorFlow 或 PyTorch。
2）也可能使用相同框架
对于一些通用的算法任务，多个算法可能使用相同的深度学习框架。例如，许多图像分类算法、目标检测算法都可以在 TensorFlow 和 PyTorch 等主流框架上实现。这是因为这些框架提供了丰富的功能和工具，能够满足不同算法的基本需求。
 2、深度学习网络
 1）不同算法通常使用不同网络
不同的算法任务往往需要不同的深度学习网络结构。例如，图像分类任务常用卷积神经网络（CNN），如 ResNet、VGG 等；而自然语言处理任务则主要使用循环神经网络（RNN）及其变体（如 LSTM、GRU）或 Transformer 架构。不同的算法目标和数据特点决定了它们需要不同的网络结构来提取特征和进行预测。
即使是同一领域的不同算法，也可能使用不同的网络结构。例如，在目标检测领域，Faster R-CNN 和 YOLO 系列算法就采用了不同的网络结构和设计理念。
2）但也存在相似之处
 某些情况下，不同算法可能会借鉴或改进现有的深度学习网络。例如，一些新的图像分割算法可能在基础的 CNN 架构上进行改进，增加特定的模块或层，以适应分割任务的需求。同时，不同领域的算法也可能会有一些共同的设计原则，如使用残差连接、注意力机制等，这些设计元素可能会在不同的算法中出现。
3、深度学习方法
1）不同算法使用不同方法
不同的算法通常会采用不同的深度学习方法。例如，在无监督学习中，自编码器和生成对抗网络（GAN）采用了不同的训练方法和目标函数。自编码器通过重构输入数据来学习数据的潜在表示，而 GAN 则通过对抗训练让生成器生成逼真的数据，同时让判别器区分真实数据和生成数据。
在强化学习中，不同的算法也有不同的策略优化方法和奖励设计。例如，深度 Q 网络（DQN）和策略梯度方法就采用了不同的方式来学习智能体的策略。
2）也可能有交叉和借鉴
不同的算法领域之间可能会有方法的交叉和借鉴。例如，半监督学习方法中的自训练和一致性正则化等技术，在图像分类和自然语言处理等不同领域都有应用。同时，一些新的深度学习方法可能会从多个领域中汲取灵感，综合不同的技术和思想来解决特定的问题。
1.2 算法应用问题
1.2.1 算法资源有没有涉及到安全和保密的资源，如算法配置、算法接口？
研究院算法库对外发布不得提供未加密的版本，加密方案安全严格按照网络安全实验室评估并推荐的方案执行。
产品部门规划智能算法相关产品时，必须先考虑加密方案，加密方案评估是智能算法可行性评估的必须项。
1.2.2 什么是人脸检测？什么是人脸比对？
人脸检测是判断图像中是否存在人脸，若存在人脸检测出人脸所在的位置。人脸比对是基于从人脸图像提取的人脸特征计算两个人脸的相似度程度，结合阈值判断是否为同一人。
1.2.3 图像质量对人脸识别是否有影响？
人脸图像质量会直接影响人脸算法的效果，与质量相关的因素包括：人脸大小（场景点位、相机选择）、清晰度（相机选型调参）、遮挡（采集对象配合度引导）、人脸姿态（相机架设、采集对象配合度引导）、光照（场景点位选择）等。
1.2.4 人脸抓拍为何会出现狗脸\车轮等非人脸？
机器学习算法的精度是个统计结果，没有算法可以做到100%的准确率。每类算法都会存在误检、漏检等异常结果。
	人脸抓拍到狗脸、车轮的情况本身只会在少数的情况下才会出现。人脸检测抓拍算法在不断迭代更新，随着版本迭代检测效果持续提升。
	若产品算法集成无误且项目中已采取算法推荐的降低误抓措施，实际项目中依然仍出现较多的狗脸、车轮的误抓，我们可以通过增加负样本训练的手段降低非人脸误检的情况。
1.2.5 为什么前端人脸抓拍成功的数据，后端设备入库失败？
前端人脸抓拍成功的数据为人脸图像，后端数据入库失败有非算法类原因和算法类原因，非算法类原因此处不做详述。
人脸识别流程中人脸建模前包括人脸检测、人脸特征点定位、人脸评分。其中人脸特征点定位为回归算法，必定会返回特征点结果，所以不存在定位失败的结果；人脸建模是从图像中提取特征，不存在提取失败的结果。建模失败算法类原因主要是检测失败（检测不到人脸）、评分过滤（某项评分值不符合要求）两类。
建议前端抓拍裁剪人脸小图同时记录人脸小图中的检测框位置，后端入库不再重新检测，那么也不存在检测失败导致的入库失败。
1.2.6 与正常成年人相比，老人小孩人脸识别效果如何？
与正常成年人相比，老人和小孩的人脸识别效果会差一些。其主要原因包括：
1、相比正常成年人，小孩五官未长开特征区分度不足，老人五官挤在一起且多皱纹特征区分度不足，因此相比正常成年人，老人小孩识别难度更大；
2、现有算法训练数据主要由正常成年人构成，老人小孩训练数据不足。
1.2.7 人脸识别中人脸关键点的数量是不是越多越好？
人脸关键点业内常见的有21、68、81、84、106、194等不同个数，更多的稠密关键点甚至超过1000个。
对于人脸识别而言关键点的作用是在人脸图像提取特征前进行图像校正处理，从校正人脸图像的角度看，只要少数几个用于校正对齐的模板点即可。因此对于人脸识别而言，只要特征点涵盖校正对齐的模板点，就能实现校正提取特征，并不是点越多越好。稠密关键点对于2D\3D卡通、虚拟形象、美妆等人脸应用很重要，但对人脸识别来说意义不大。
二.	大模型问题
2.1 大模型通识问题
2.1.1 大模型和小模型有什么区别？
大模型和小模型的区别主要体现在以下几个方面：
1、模型结构的差异
小模型以CNN为技术架构，大模型主要以Transformer为技术架构。由于结构差异，模型参数量也存在差异，小模型通常在百万-千万级，大模型亿级起步
2、预训练方式的差异
小模型基于有监督预训练，利用标注数据对模型进行训练，以学习特定任务的规律和模式。优势在于学习效率高，缺点在于对标签强依赖，而有标签数据集的构建成本非常高。
大模型通常基于多模态预训练结合自监督预训练方式来完成预训练。多模态预训练是利用图文数据对，利用图文对比学习的方式进行预训练，优势在于利用与图像匹配的文本作为监督信号进行学习，降低了对标签的依赖，同时极大丰富了用于预训练的视觉概念数量。自监督预训练使用无标签图像数据进行预训练，不需要任何人工标定的监督信息，最大程度上降低了对标签的依赖。
3、预训练数据规模
对于预训练数据规模也会存在差异，小模型数据规模为百万-千万级，大模型数据规模为亿级以上。
2.1.2 CNN和transformer有什么区别？
CNN（卷积神经网络）和Transformer都是深度学习中非常重要的模型结构，在不同领域都有广泛的应用。之前CNN主要应用于处理图像等空间结构数据；而Transformer前期主要应用于自然语言处理中的序列数据，后面经过发展逐步用于图像、语音等数据处理，并有更好的性能表现。
它们的区别主要体现在以下几个方面：
性能方面：受益于全局建模能力和动态注意力机制，Transformer吸收海量知识的能力更强；具体表现出来的就是它的性能上限更高，在相同参数量下性能也更高
计算资源方面：相比于CNN，Transformer计算复杂度相对较高，因为自注意力机制需要计算所有序列位置之间的相似度，不能利用卷积等局部计算方法，因此需要更多的计算资源。
2.1.3 大模型训练和原先深度学习小模型训练有什么区别？
大模型训练和原先深度学习小模型训练的区别在以下几个方面：
1、数据要求
大模型需要极其庞大的数据量来进行训练，预训练的数据规模为亿级以上；小模型对数据量的需求相对较小，一般在百万或千万级别。
2、	模型架构
小模型以CNN为模型架构，大模型主要以Transformer为模型架构。由于结构差异，模型参数量也存在差异，小模型通常在百万-千万级，大模型亿级起步
3、训练策略
小模型基于有监督预训练，利用标注数据对模型进行训练，以学习特定任务的规律和模式。大模型通常采用无监督预训练方式学习通用的知识，然后根据具体的任务进行微调以适应特定的任务需求；这种预训练+微调的方式可以充分利用大规模数据的优势，提高模型的性能和泛化能力。
4、计算资源
大模型由于数据量大、模型复杂，训练大模型需要较长的时间、强大的计算能力和大量的存储资源；反之小模型对计算资源要求相对较低、训练时长较短。
2.1.4 怎么理解大模型的参数和数据？两者之间有什么样的关系？
1、参数量和数据的理解
1）参数量越大，模型能容纳的知识量也就越大，能力上限也就越高，同时占用的计算资源和存储资源也就越大；
2）参数量越大的模型需要喂给它越多的数据，让他学习到的知识越多，他的能力越强，越全面
2、参数和数据的关系
小参数+大数据，模型学不会，会遗忘
大参数+小数据：模型会学的偏执，过拟合
大参数+大数据：模型能力全面，强大
3、预训练阶段和任务模型训练阶段参数量和数据量的关系
预训练阶段，参数量越大、数据量越大，底座能力越强
任务模型训练阶段，在相同底座能力下数据越多能力越强。
2.1.5 大模型开发过程中使用的工具链是什么？开发环境，开发工具，开发库？训练和推理使用的编程语言是什么？
大模型开发过程中通常使用的：
1、工具链通常包括数据处理工具（数据采集、清洗、标注工具）、模型开发工具（深度学习框架、模型可视化工具、模型调优工具）、算力管理工具（分布式训练框架、资源调度工具）、模型评估与验证工具、部署与监控工具。
2、常用的开发环境基于Linux操作系统,使用深度学习框架如PyTorch、TensorFlow等、编程语言通常使用Python、C++、硬件加速通常使用CUDA、TensorRT等技术；常用的开发资源包括transformer、huggingface等。 
2.1.6 基础大模型、行业大模型、任务大模型有什么区别？
基础大模型是指可以在多个领域和任务上通用的大模型。它们利用大算力、使用海量的开放数据与具有巨量参数的深度学习算法，在大规模无标注数据上进行预训练，以寻找特征并发现规律，进而形成可“举一反三”的强大泛化能力，可在不进行微调或少量微调的情况下完成多场景任务，相当于AI完成了“通识教育”。通用大模型的代表有OpenAI开发的GPT系列。
行业大模型是指那些针对特定行业或领域的大模型。它们通常使用行业相关的数据进行预训练或微调，以提高在该领域的性能和准确度，相当于AI成为“行业专家” 。行业大模型的代表有谷歌开发专注医疗健康的 Med-PaLM 2。
任务大模型是指那些针对特定任务或场景的大模型。它们通常使用任务相关的数据进行预训练或微调，以提高在该任务上的性能和效果。
2.1.7 各个厂家的基础大模型区别大吗？
基础大模型各个厂家存在较大的区别，在大模型的类型、参数规格、主要应用方向上都存在差异。比如大模型的类型有视觉大模型、语言大模型、多模态大模型、物联感知大模型等；大模型的参数规格上，亿级到万亿级不等，如视觉大模型最大是百亿级、语言大模型则有万亿级；应用方向上，根据不同的大模型类型可用于不同的应用领域，比如语言大模型侧重于问答理解类、推理类、创作表达类、数学类、代码类等应用。
2.1.8 什么是知识蒸馏？
知识蒸馏的概念，是指把一个大模型或者多个模型学到的知识迁移到另一个轻量级单模型上，方便部署。简单的说就是用小模型去学习大模型的预测结果，而不是直接学习训练集中的标签。
知识蒸馏采取教师-学生模式：将复杂且大的模型作为教师，学生模型结构较为简单，用教师来辅助学生模型的训练，教师学习能力强，可以将它学到的知识迁移给学习能力相对弱的学生模型，以此来增强学生模型的泛化能力。复杂笨重但是效果好的教师模型不上线，就单纯是个导师角色，真正部署上线进行预测任务的是灵活轻巧的学生小模型
其核心思想是因为好模型的目标不是拟合训练数据，而是学习如何泛化到新的数据。所以蒸馏的目标是让学生模型学习到教师模型的泛化能力，理论上得到的结果会比单纯拟合训练数据的学生模型要好。
2.1.9 大模型与蒸馏后的小模型的区别？
为了方便大家更好的理解，我们以“英语四级考试”为例：
假设我要参加英语四级考试，自己能力能考450分，后来找了专业英文老师培训，经过培训能考500分。在这个过程中，培训老师可以看做是大模型，培训之前的自己是小模型，培训之后的自己是蒸馏模型。
蒸馏后的模型仍然是小模型（参数量、模型大小均不发生变化），大模型和蒸馏后的小模型在精度和算力消耗上存在区别，包括：
精度：大模型＞蒸馏后的小模型
算力消耗：大模型＞蒸馏后的小模型
2.1.10 关于大模型蒸馏成小模型的技术，各个厂家的方案是否一样？
不同厂家蒸馏方法存在差异，比如学生学习教师的内容不一样（如权重表达）、学习的程度也不一样（效果上的权衡，我们的蒸馏技术根据任务做自适应）。
海康蒸馏技术优势：自研蒸馏技术，可实现大模型向端边缘小模型的有效知识迁移，该技术在AI开放平台中上线，可将小模型与大模型的性能差异平均缩小50%以上。
2.1.11 语言大模型、视觉大模型、多模态大模型之间的区别？
语言大模型主要处理自然语言文本数据，通过在大型文本语料库上进行训练，学会理解语言的结构、语义、语境和语用等方面，具有强大的文本生成和语义理解能力。在对话系统、问答系统等领域有广泛应用。
视觉大模型主要处理图像、视频等数据，通过从视觉信息中提取有用的特征和模式，用于各种视觉任务，如图像分类、目标检测等。
多模态大模型能够处理图像、文本、音频等多种不同类型的数据，通过大规模的数据训练，学习如何联合理解和生成跨多种模式的信息，在视觉问答、图像描述生成等领域有广泛应用。
2.1.12 通用大模型到行业大模型，输入的是带标注的数据吗？
基于基础大模型微调生成行业大模型，在这个过程中需要输入带标注的数据。高质量标注数据对模型的性能至关重要。数据类别需要丰富，数据场景要丰富，各个类别之间的数据需要保持均衡。
2.1.13 大模型训练各环节有多大规模数据输入？是否有标注？在微调阶段数据量对模型性能的影响（多少量级是门槛？）
以语言模型为例，大模型训练一般分预训练、对齐学习，对齐又分监督微调、奖励模型微调、RLHF微调，以ChatGPT为例，在预训练阶段有万亿的文本数据（包含了大量无监督数据），在有监督微调、奖励建模以及强化学习阶段，则需要投入1万到百万级别的高质量数据做监督训练。
微调阶段数据量级不固定，需要看具体的任务类型，有些几百张就可以达到较好的效果。部分要求精度高的任务需要较多的数据。
2.1.14 视觉大模型起训数据量减少多少？人工标注提效多少？ 
以AI开放平台为例起训数据量减少90%，人工标注效率提升50%；
2.1.15 视觉大模型一定要输入数据吗？Zero-shot可行吗？为什么通用大模型不能解决所有问题？
视觉大模型需要根据任务的难易程度，期望达到的效果和模型本身的能力有关，不一定都需要输入数据。
通用大模型一般都是基于广泛的公开文献与网络信息来训练的,网上的信息可能有错误、有谣言、有偏见,许多专业知识与行业数据积累不足,导致回答的行业针对性与精准度不够,输出的信息也相对宽泛。
虽然通用大模型整体水平在不断提升。细分行业领域的数据，网上是很缺乏的，比如金融、医疗领域，数据是无法完全对外开放的。因此，通用大模型无法解决所有的问题。
2.1.16 用大模型是否可以降低算法对输入图片的要求？比如图片像素、目标大小、人脸瞳距等要求？
不可以。大模型的性能与数据的质量有很大的关系。
2.2 海康大模型基础问题
2.2.1 海康大模型名字叫什么？
海康观澜大模型
2.2.2 海康大模型有什么技术优势？
1、海康大模型具有全面的感知能力，海康威视构建了包括可见光、热成像、雷达、X光等电磁波，声波、超声波等机械波，以及多种物理传感技术的全面感知体系，助力打造了具备多维感知能力的大模型。
2、海康威视在智能物联领域具有20多年的积累，为了满足更多行业用户的智能化需求，我们面向交通、电力、钢铁、煤炭、安检等诸多垂直行业，结合高质量的领域数据和领域知识，打造行业大模型。海康威视进行了大规模预训练生产基础大模型，吸收通用知识，再加入行业数据进行微调生产行业大模型，在保留了基础大模型的高泛化能力基础上具备了专业的行业能力。“预训练基础大模型+行业微调”的开发范式大大提高了AI模型开发的效率和跨场景泛化能力，构建了领先的行业应用能力。
3、海康观澜大模型针对海康威视丰富的云边端产品线，构建了包括模型精简、蒸馏在内的完整的硬件部署技术体系。自研模型精简技术，同结构大模型压缩后部署对比fp16精度部署，可实现资源占用15倍以上高效压缩，实际推理加速达到10倍以上。自研蒸馏技术，可实现大模型向端边缘小模型的有效知识迁移，该技术在AI开放平台中上线，可将小模型与大模型的性能差异平均缩50%以上。
2.2.3 海康大模型的瓶颈是什么？
目前行业内各个厂家的大模型都存在一定的局限性，大模型面临的主要瓶颈包括内容安全性、内容失真、运行成本高等几个方面。
内容安全性：细颗粒度感知能力不足，会生成有害、偏见等内容；
内容失真：生成看似合理但实际错误的虚假事实，存在视觉幻想，会输出图像中不存在的内容；
运行成本高：大模型需要大算力支撑。
2.2.4 海康大模型训练数据来源有哪些？
海康观澜大模型的数据来源包括：开源数据集、海康自采数据、商业采购数据。
1、开源数据集，在验证开源数据集的授权协议，确保可以用于模型训练后按要求使用。
2、海康自采数据主要是配合式采集数据，是指使用摄像机、手机等采集设备，在专门搭建的模拟场景中，经特定被采集人授权同意采集所需数据的形式。
3、商业采购数据，在与供应商签署协议，确保有充分授权后进行使用。
2.2.5 海康大模型的参数量有多少？
海康大模型为谱系模型，不同的模型参数量不一样，其中：
视觉大模型为亿级-十亿级不等，语言大模型为亿级-百亿级不等，多模态大模型为亿级-百亿级不等。
2.2.6 海康大模型底层的架构、参数量、算力要求是怎么样的？是否开源架构，代码层是否开放？？
海康观澜大模型采用自研的底层架构，参数量根据大模型形态的不同，在几十亿到几百亿不等。大模型的算力需求是非常巨大的，具体需求取决于模型的大小、复杂度和训练阶段。
海康观澜大模型的架构不是开源的，代码层不对外开放。
2.2.7 海康大模型应用架构中，云端和边缘端大模型部署架构的区别，各自的优劣势？
1、边缘部署：将大模型及小模型部署在边缘端设备（如智能分析服务器、智能NVR等）的不同性能的GPU上，并利用这些设备的计算资源进行推理的方法。
适用场景：适用于数据隐私性、实时性要求高的应用场景，已经在制造、能源、电力、煤矿等行业得到广泛应用，并取得良好的应用效果
优势：①针对部分边缘端智能设备计算资源有限，无法直接部署大模型的问题，海康威视通过异构蒸馏技术手段，将大模型的知识部分迁移到小模型上，这使得小模型能够顺利部署至此类智能设备上，降低了大模型的使用门槛，为用户提供高性价比的方案。②由于数据无需传输到云端，因此可以保护用户隐私和敏感信息，有效保障数据的安全性。③由于大模型及小模型直接部署在边缘设备上，可以有效降低网络传输延迟和带宽限制所带来的影响，实现快速响应和高效处理。
2、云端部署：将大模型部署在云端AI推理集群中，借助云计算平台的强大计算能力完成处理数据和计算任务的方法。这种技术的优势在于利用云计算平台的规模效应和资源共享，从而降低推理成本。
适用场景：适用于数据敏感性和实时性要求较低的联网场景，例如零售、连锁和酒店等行业。
2.2.8 小公司基于开源大模型的方案是否可以达到海康大模型同等的性能？
小公司基于开源大模型的方案不一定能达到海康大模型同等的性能，海康和它们相比存在如下技术优势，包括：
1、海康大模型除了具备通识知识以外，还有大量的业务知识，以及针对海康业务需求特定实现的功能，在具备通用能力之外能更好适配自身业务；
2、目前开源大模型往往只开源模型参数，而对于训练数据构建方法、训练策略都没有开源，即使拿到开源模型参数，在特定的应用领域微调，效果很难保证有竞争力。海康大模型完全自主研发，全部过程都可以进性精细优化，因此构建了训练和应用门槛；
3、海康大模型从结构设计、部署方案都充分参考了海康产品硬件规格，能够做到比开源模型更高的运算效率。
2.2.9 海康大模型如何保证数据的安全隐私性（业务中的数据主要在什么阶段使用，如何使用以及如何保证数据安全隐私）？
海康的数据的安全隐私性保护主要以下几种方式：
数据隔离：具备用户数据隔离，不可访问未授权数据。采用分区技术，保障 同一用户不同子帐号、不同项目组数据的隔离。 
数据加密：采用AES-128加密机制对数据进行传输加密和存储加密，并且 每个用户具备独立加密密钥；采用RSA非对称加密生成模型的授权文件。 
设施保护：采用硬件防火墙防护网络边界，部暑WAF用于对业务请求导常 检测，所有主机安装HIDS实时检测主机入侵，访问主机须经过堡垒机。 
身份认证：采用 HTTPS 加密协议诵信，对所有请求进行身份认证，使用 Access Key 机制向第三方开发者颁发 AK和SK，并建立黑白IP名单安全管挖机制。 
数据高可用：采用高可用架构和分布式数据存储技术，实现数据导地多副本 冗杀，自动执行全量和增量备份，以保障数据高可用性。
2.2.10 海康大模型针对虚假/内容失真的问题如何处理？幻觉问题是仅针对语言相关吗 ？
CV大模型不会出现此类问题，CV大模型中会出现误报及漏报问题。语言大模型及多模态大模型会出现此类问题，属于视觉幻想问题，需要通过一系列的技术手段，比如人工反馈的强化学习、高质量的数据治理等来缓解。
2.2.11 大模型对硬件设备有什么要求？是否支持在CPU上运行？
大模型对硬件设备的要求较高，我们目前暂时支持T4、KT2、H9芯片设备的部署。
运行大模型所需的算力较大，暂不支持在CPU上运行。
2.2.12 已部署的项目能不能升级到大模型？
已建项目可以通过平台下发大模型进行分析，由于使用大模型后需要消耗资源更多，会导致原有设备分析路数降低。
现场也可以通过增加超脑/云端服务等形式部署大模型，对报警信息进行二次分析过滤。
2.2.13 以前的都是小模型，是否有必要都升级到大模型，大、小模型适用场景差异性？
需要综合考虑场景的实时性要求、成本、泛化性要求等条件。可以直接部署大模型，可以使用蒸馏模型，也可以通过大模型做二次过滤。
2.2.14 客用户对大模型最直观的了解chatgpt、文心一言等，如何专业又易懂地向客用户介绍海康大模型？能讲出来区别和我们的专业性？
首先基础模型的能力层面，海康大模型除了常规的视觉大模型、语言大模型、多模态大模型能力外，还有物联感知的大模型能力，得益于海康构建的全面感知能力，能够获取到全面模态的丰富数据。
基础模型面向行业应用，我们有丰富的行业知识积累，通过“预训练基础大模型+行业微调”的方式来保障高泛化能力与专业行业能力。
面向云边端多级部署的特点，海康从模型轻量化、计算效率提升、计算资源节省三方面研究了蒸馏技术、模型结构设计技术和量化技术等，构建了完善的大模型部署体系。
2.2.15 如果用越大的通用大模型，叠加行业数据，训练出来的行业大模型效果会越好吗？
不一定，通用大模型只是一个基底，行业大模型的效果好坏，跟加入的行业数据量大小和质量也强相关。
2.3 海康大模型应用问题
2.3.1 海康大模型常见的的部署方式有哪些？对于设备有什么要求？
针对不同的边缘设备，大模型部署方案不一样，对于设备的要求也不一样：
1、基于通用大模型，使用行业相关的数据进行预训练或微调得到的行业大模型，可以直接进行部署，部署在云中心或者边缘域（比如智能分析服务器、智能NVR）。此种情况下需要较高算力的设备，如T4服务器 、KT2平台超脑、H9平台的摄像机等。
2、针对部分边缘端设备计算资源有限，无法直接部署大模型的问题。可以通过知识蒸馏技术，将大模型的知识部分迁移到小模型，使得小模型直接部署在设备端。此种情况下常规带算力的设备即可支持，如智能警戒摄像机、AI开放平台摄像机等。
3、边缘设备部署小模型提高目标的检出能力，云端或后端部署大模型进行二次过滤降低误报率，此种情况下需要较高算力的设备，如T4服务器、KT2平台超脑。
2.3.2 海康多模态大模型有哪些应用？
以文搜图、万物检测、行为分析（打架、倒地）、图文对话等。
2.3.3 大模型和AI开放平台是怎么结合的？具体操作上和原来的AIOP算法有什么区别？在AI开放平台上如何区分？ 
官网开放能力方面，上架的算法能力基本上都使用了大模型，模型导出的时候训练网络可选择“超高精度”项即为大模型。
模型训练方面，通过开放平台检测、分类、混合训练任务都已支持大模型的训练。我们提供了多样的大模型训练模式：
1）超高精度训练模式：训练模式选择“超高精度”（如下左图），基于观澜基础大模型底座，结合用户场景数据共同训练得到超高精度大模型；
2）蒸馏训练模式：训练模式选择“高级训练”（如下右图），通过知识蒸馏技术，实现大模型向端侧边缘小模型的有效知识迁移，将大模型良好的精度水平和强大的泛化能力快速迁移到小模型中，从而获得蒸馏模型。
   
2.3.4 海康大模型能否部署到第三方服务器？
商务问题，符合海康大模型落地硬件规格的前提下，技术上可行，但不推荐
2.3.5 第三方自研小模型能否使用海康大模型进行二次过滤？
可以。
将第三方小模型分析的结果给到支持大模型能力的海康设备进行二次分析过滤。 
不同的项目实现方案有所不同，比如给到大模型设备分析的是图片还是视频、大图还是小图、二次分析使用的技术方案（检测或分类）等，具体需求具体讨论。
2.3.6 一个算法里有多种标签，但是每个标签的素材量差距非常大，比如同样是鸟，麻雀素材很多，但老鹰素材很少，是否容易将老鹰识别成麻雀，同时检测时大模型能拉平衡么？
同样素材及场景下，大模型版本效果会有提升。但是大模型只是减少了原始任务模型训练数据的依赖，但是对于特定的类别还是需要加入少量数据。
2.3.7 政府想要私有化部署大模型怎么实施？
【大模型的推理】
中心侧：按需部署通用大模型或者行业大模型
端侧：部署行业大模型进行知识蒸馏后的蒸馏模型
【大模型的训练】
一事一议
2.3.8 有没有大模型的演示环境？ 
视觉大模型可以在AI开放平台官网进行在线体验。
多模态大模型可以在技术推广部公众号进行在线体验，具体路径为“hiklink研究院技术推广部公众号-服务提供-大模型演示”，账号和密码申请可联系陈琦29/邵毅6。
